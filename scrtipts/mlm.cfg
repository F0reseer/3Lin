connect_data_server('localhost')

# train params
SAVE_MODEL = false
MAX_ITERS = 2000000
EVAL_INTERVAL = 100
EVAL_BATCH_COUNT = 20
TRAIN_CONFIG = 'b32f513'
# DROP_CONFIG = 'drop1ch1' # default step is too large
DROP_CONFIG = 'drop1ch1lr0.001'

# model width, depth
#MODEL_DIMS = 'e512tt128d60w512'
MODEL_DIMS = 'e768d80w512'
create_model(MPF_MLM_BERT, MPF_TUNE_FINAL_LAYER, MPF_TUNE_EMBED)

train()
