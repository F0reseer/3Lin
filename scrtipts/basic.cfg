# load data
#USE_PPM = true
make_char_dataset('D:/111enwiki9/wiki7_filter.txt')
#connect_data_server('localhost')
#save_dataset('d:/dataset.bin')
#load_dataset('d:/dataset.bin')

# train params
SAVE_MODEL = false
MAX_ITERS = 2000000
EVAL_INTERVAL = 1000
EVAL_BATCH_COUNT = 20

# batch, window, sliding window
TRAIN_CONFIG = 'b64f64'
#TRAIN_CONFIG = 'b256f64'
#TRAIN_CONFIG = 'b64f256'
#TRAIN_CONFIG = 'b16f1024'
#TRAIN_CONFIG = 'b4f4096'

# dropout, learning rate
#DROP_CONFIG = 'drop0.9ch0.9'
DROP_CONFIG = 'drop0.9ch0.9reg2000'
#DROP_CONFIG = 'drop0.8ch0.8'

# model width, depth
#MODEL_DIMS = 'e256d1'
MODEL_DIMS = 'e256d65' # 25M, default
#MODEL_DIMS = 'e512d65' # 50M
#MODEL_DIMS = 'e512h2d65'
#MODEL_DIMS = 'e1024tt256d65w1024' # profile
#MODEL_DIMS = 'e2048tt256d96w4096'
#create_model(MPF_TAIL_LOSS)
create_model(MPF_TAIL_LOSS, MPF_TUNE_FINAL_LAYER, MPF_TUNE_EMBED)
#create_model(MPF_TAIL_LOSS, MPF_ABS_POSITIONS, MPF_TUNE_FINAL_LAYER, MPF_TUNE_EMBED)
#load_checkpoint(150000)

train()
#net_train('d:/workers_local.txt')
#compute_exact_test(75000,5000)
#load_model('D:/models/fed_small/model_192.bin')
#compute_exact_test()
